{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction :\n",
        "\n",
        "Dans ce projet, je me concentre sur deux tâches principales : l'extraction des entités et la détection des signatures dans des documents PDF, spécifiquement pour des modèles de contrats d'assurance.\n",
        "\n",
        "L'objectif est d'extraire les informations essentielles contenues dans ces documents, telles que le nom de l'assuré, l'adresse, la date d'effet, le Numéro d'assurance, le Montant de la Couverture et la Réduction ainsi que d'identifier si le document est signé par les deux parties concernées.\n",
        "\n",
        "Ce traitement est effectué sur des documents structurés selon un modèle spécifique (le PDF fourni), où les informations clés sont souvent répétées et placées à des positions précises dans le texte. Pour cela, j'utilise des techniques de reconnaissance de texte et d'analyse d'images, permettant d'automatiser l'extraction des données importantes et la détection des signatures après des mots-clés comme \"Yours sincerely\", typiques de la conclusion d'un contrat."
      ],
      "metadata": {
        "id": "O14e9L3Mj4c-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "NkpPP7rm1zLX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snb2FU5Lw9CV",
        "outputId": "f970a073-5d87-4daf-afbe-de38a902fd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2 pdfplumber spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Extraction des Entités :"
      ],
      "metadata": {
        "id": "f3MLp4vQ2Bpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "import csv"
      ],
      "metadata": {
        "id": "E80Ah7vy2mAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction pour extraire le Nom et l'Adresse de l'assuré :\n",
        "\n",
        "Cette Fonction extrait le nom et l'adresse d'un assuré à partir d'un texte brut issu d'un PDF. Elle repose sur l'hypothèse que tous les PDF suivent un format fixe où :\n",
        "\n",
        "1) Le nom de l'assuré est toujours précédé de \"Mr\" ou \"Ms\".\n",
        "\n",
        "2) L'adresse commence immédiatement après la ligne contenant le nom et se termine par une ligne contenant un code postal à 4 chiffres suivi d'une ville.\n",
        "\n",
        "La fonction parcourt ligne par ligne le texte, détecte le nom via un motif regex, puis capture les lignes suivantes comme étant l'adresse jusqu'à la détection du code postal. Grâce à cette hypothèse de format constant, elle garantit une extraction cohérente et précise des informations."
      ],
      "metadata": {
        "id": "UrvYFz352qwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_name_and_address(text):\n",
        "    # Diviser le texte en lignes en utilisant le caractère de nouvelle ligne \"\\n\"\n",
        "    lines = text.split(\"\\n\")\n",
        "\n",
        "    # Définition d'un motif(pattern) pour détecter un nom précédé de \"Mr\" ou \"Ms\" suivi d'un ou plusieurs noms.\n",
        "    # Supposition : Le texte suit toujours le même modèle, où le nom est précédé par \"Mr\" ou \"Ms\".\n",
        "    name_pattern = r\"^(Mr|Ms)\\s+([A-Za-z\\s]+)$\"\n",
        "\n",
        "    # Définition d'un motif pour détecter un code postal à 4 chiffres suivi d'une ville\n",
        "    postal_code_pattern = r\"^\\d{4}\\s+[A-Za-z\\s]+$\"\n",
        "\n",
        "    # Initialisation des variables pour stocker le nom et les lignes d'adresse\n",
        "    name, address_lines = None, []\n",
        "\n",
        "    # Indicateur pour savoir si on doit commencer à capturer l'adresse\n",
        "    is_address = False\n",
        "\n",
        "    # Boucle sur chaque ligne extraite du texte\n",
        "    for line in lines:\n",
        "        # Si la ligne correspond au motif du nom (nom de l'assuré), on la stocke\n",
        "        match = re.match(name_pattern, line.strip())\n",
        "        if match:\n",
        "            # Si le titre est \"Mr\" ou \"Ms\", on extrait uniquement la partie du nom (sans le titre)\n",
        "            name = match.group(2).strip()  # Enlève les espaces en début/fin de ligne et stocke le nom sans \"Mr\" ou \"Ms\"\n",
        "            is_address = True    # Active la capture des lignes suivantes pour l'adresse\n",
        "\n",
        "        # Si l'indicateur \"is_address\" est activé, on commence à traiter l'adresse\n",
        "        elif is_address:\n",
        "            # Vérifie si la ligne correspond au motif du code postal (fin de l'adresse)\n",
        "            if re.match(postal_code_pattern, line.strip()):\n",
        "                address_lines.append(line.strip())  # Ajoute la ligne de l'adresse\n",
        "                break  # Arrête la capture après avoir trouvé la ligne de code postal\n",
        "            # Si la ligne n'est pas vide, elle est ajoutée comme partie de l'adresse\n",
        "            elif line.strip():\n",
        "                address_lines.append(line.strip())\n",
        "\n",
        "    # Concatène les lignes d'adresse en une seule chaîne ou indique \"Non trouvé\" si vide\n",
        "    address = \" \".join(address_lines) if address_lines else \"Non trouvé\"\n",
        "\n",
        "    # Retourne un dictionnaire contenant le nom et l'adresse de l'assuré\n",
        "    return {\"Nom de l'assuré\": name, \"Adresse de l'assuré\": address}\n"
      ],
      "metadata": {
        "id": "khJS9-dR22ft"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction pour extraire la date d'effet :\n",
        "\n",
        "Cette fonction extrait la date d'effet, c'est-à-dire la première date mentionnée dans le texte qui correspond au format \"Jour Mois Année\" ( \"17 January 2024\").\n",
        "\n",
        "\n",
        "1) Diviser le texte en lignes : Le texte est d'abord divisé en lignes pour faciliter la recherche.\n",
        "\n",
        "2) Définir un motif de recherche pour la date d'effet: (expression régulière) est utilisé pour rechercher une date dans le format Jour Mois Année.\n",
        "\n",
        "3) Retour de la date d'effet : Si une date est trouvée, elle est renvoyée comme date d'effet. Si aucune date n'est trouvée, la fonction renvoie \"Non trouvée\"."
      ],
      "metadata": {
        "id": "Otv-m9fON6jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_date(text):\n",
        "    # Diviser le texte en lignes\n",
        "    lines = text.split(\"\\n\")\n",
        "\n",
        "    # Définir un motif pour détecter une date au format : Jour Mois Année ( \"17 January 2024\")\n",
        "    date_pattern = r\"\\b\\d{1,2}\\s+(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b\"\n",
        "\n",
        "    # Initialiser la variable de la date\n",
        "    extracted_date = None\n",
        "\n",
        "    # Parcourir chaque ligne pour rechercher une date\n",
        "    for line in lines:\n",
        "        match = re.search(date_pattern, line.strip())\n",
        "        if match:\n",
        "            extracted_date = match.group(0)\n",
        "            break  # Arrêter dès qu'une date est trouvée\n",
        "\n",
        "    # Retourner la date ou \"Non trouvée\"\n",
        "    return {\"Date\": extracted_date if extracted_date else \"Non trouvée\"}"
      ],
      "metadata": {
        "id": "dJvsS5qPHhXm"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction pour extraire le Numéro d'assurance"
      ],
      "metadata": {
        "id": "W3em0grY5KHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction extrait le numéro d'assurance à partir d'un texte brut :\n",
        "\n",
        "1) Format fixe : La fonction repose sur l'hypothèse que tous les PDF suivent un format où le numéro d'assurance est précédé de l'expression \"insurance no.\".\n",
        "\n",
        "2) Utilisation de regex : Un motif regex est utilisé pour repérer \"insurance no.\" suivi d'un ou plusieurs chiffres et espaces.\n",
        "\n",
        "3)Résultat : Si une correspondance est trouvée, le numéro est extrait et les espaces superflus sont supprimés. Sinon, la fonction retourne \"Non trouvé\".\n",
        "\n"
      ],
      "metadata": {
        "id": "HZK2exwX5tX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_insurance_number(text):\n",
        "    match = re.search(r\"insurance no\\.\\s+([\\d\\s]+)\", text)\n",
        "    return match.group(1).strip() if match else \"Non trouvé\""
      ],
      "metadata": {
        "id": "3PzRG4xL5aU2"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour extraire le Montant de la Couverture"
      ],
      "metadata": {
        "id": "3I2sW67t6BFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction extrait le montant de la couverture (prime mensuelle totale en CHF) :\n",
        "\n",
        "1) Hypothèse de format fixe : Le texte suit toujours un modèle où la phrase \"Total monthly premium in CHF payable by you\" est suivie du montant sous forme numérique avec deux décimales (ex. : 1234.56).\n",
        "\n",
        "2) Utilisation de regex : La fonction utilise un motif regex pour repérer cette phrase et extraire le montant correspondant.\n",
        "\n",
        "3) Résultat :\n",
        "Si le montant est trouvé, il est directement retourné.\n",
        "Si aucune correspondance n'est détectée, la fonction retourne \"Non trouvé\"."
      ],
      "metadata": {
        "id": "6wHvhNPq6G58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_coverage_amount(text):\n",
        "    match = re.search(r\"Total monthly premium in CHF payable by you\\s+(\\d+\\.\\d{2})\", text)\n",
        "    return match.group(1) if match else \"Non trouvé\""
      ],
      "metadata": {
        "id": "XWSUMmml6GZK"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour extraire la Réduction"
      ],
      "metadata": {
        "id": "SjJk9QEJ6o6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction extrait toutes la réduction Totale :\n",
        "\n",
        "1) Hypothèse de format : La réduction est indiquée sous la forme \"total discount ... CHF [montant]\".\n",
        "\n",
        "2) Extraction avec regex :\n",
        "Le motif regex détecte les réductions sous forme numérique (ex. : 150.00). Le montant extrait est nettoyé des espaces superflus.\n",
        "\n",
        "3) Résultat : La fonction retourne la réduction Totale.\n"
      ],
      "metadata": {
        "id": "eCSULXhD6pUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_discount_from_all_pages(pdf):\n",
        "    all_discount = []  # stocker toutes les réductions extraites\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        match_reduction = re.search(r\"total discount.*?CHF\\s([\\d\\.]+)\", text, re.IGNORECASE)\n",
        "        if match_reduction:\n",
        "            reduction = match_reduction.group(1).strip()\n",
        "            if reduction not in all_discount:  # Eviter les doublons\n",
        "                all_discount.append(reduction)\n",
        "    return all_discount"
      ],
      "metadata": {
        "id": "NIbf5u1N6pgy"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction pour extraire le Nom de l'Assureur"
      ],
      "metadata": {
        "id": "aU2KWKsb7dQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction extrait le nom de l'assureur à partir du pied de la page :\n",
        "\n",
        "1) Hypothèse de format : Le nom de l'assureur est toujours situé dans les quatre dernières lignes du texte, généralement dans le pied de page.\n",
        "\n",
        "2) Extraction des lignes du pied de page : La fonction sélectionne les quatre dernières lignes pour concentrer la recherche.\n",
        "\n",
        "3) Recherche par regex :\n",
        "Le motif regex détecte les noms propres (mots commençant par une majuscule suivis de lettres minuscules, avec des espaces optionnels entre eux).\n",
        "Les lignes contenant des URLs, des extensions (.com, .ch) ou des chiffres sont exclues pour éviter de fausses correspondances.\n",
        "\n",
        "4) Résultat :\n",
        "Si un nom correspondant est trouvé, il est retourné après suppression des espaces superflus.\n",
        "Si aucun assureur n'est détecté, la fonction retourne \"Non trouvé\"."
      ],
      "metadata": {
        "id": "LrTqkoYo7d-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_insurer_from_footer(text):\n",
        "    lines = text.split(\"\\n\")\n",
        "    footer_lines = lines[-4:]  # Dernières lignes de la page\n",
        "    potential_insurer = None\n",
        "\n",
        "    for line in footer_lines:\n",
        "        # Recherche de noms propres\n",
        "        if re.search(r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\", line) and not re.search(r\"(www\\.|\\.com|\\.ch|\\d+)\", line):\n",
        "            potential_insurer = line.strip()\n",
        "            break\n",
        "\n",
        "    return potential_insurer if potential_insurer else \"Non trouvé\""
      ],
      "metadata": {
        "id": "Ag9E-YLL7ePP"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test  :"
      ],
      "metadata": {
        "id": "5ARXBTHN8Wlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des entités du document\n",
        "pdf_path = \"/content/insurance-policy-example.pdf\"\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    text_first_page = pdf.pages[0].extract_text()\n",
        "\n",
        "    extracted_info = {}\n",
        "    extracted_info[\"Nom de l'assuré\"], extracted_info[\"Adresse de l'assuré\"] = extract_name_and_address(text_first_page).values()\n",
        "    extracted_info[\"Numéro d'assurance\"] = extract_insurance_number(text_first_page)\n",
        "    extracted_info[\"Montant de la couverture\"] = extract_coverage_amount(text_first_page)\n",
        "    extracted_info[\"Nom de l'assureur\"] = extract_insurer_from_footer(text_first_page)\n",
        "    extracted_info[\"Date\"] = extract_date(text_first_page)[\"Date\"]\n",
        "    all_discount = extract_discount_from_all_pages(pdf)\n",
        "    extracted_info[\"Réduction\"] = \", \".join(all_discount) if all_discount else \"Non trouvé\"\n",
        "\n",
        "# Affichage des résultats\n",
        "for key, value in extracted_info.items():\n",
        "    print(f\"{key}: {value if value else 'Non trouvé'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppcGyX4hzdt7",
        "outputId": "6f6b0b6f-e28b-4983-c681-7397657db825"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nom de l'assuré: Charles Muster\n",
            "Adresse de l'assuré: Feldlerchenweg 15 3360 Herzogenbuchsee\n",
            "Numéro d'assurance: 100 452 956\n",
            "Montant de la couverture: 863.55\n",
            "Nom de l'assureur: Helsana Versicherungen AG\n",
            "Date: 17 January 2024\n",
            "Réduction: 7.50.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stocker les données extraites dans un Fichier CSV"
      ],
      "metadata": {
        "id": "IsJBJ7Jy_TFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/extracted_info.csv\"\n",
        "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=extracted_info.keys())\n",
        "\n",
        "    # Écriture de l'en-tête\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Écriture des données extraites\n",
        "    writer.writerow(extracted_info)\n",
        "\n",
        "print(f\"Les informations extraites ont été enregistrées dans {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMafzXbs9Aup",
        "outputId": "10dc8718-d9d8-44be-fffd-08d5ecd4af80"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les informations extraites ont été enregistrées dans /content/extracted_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Détection de Signatures :"
      ],
      "metadata": {
        "id": "7m9XkKNf_rk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Conversion de la dernière page du PDF en image : La première étape consiste à convertir la dernière page du PDF en image, car cette page contient généralement les signatures.\n",
        "\n",
        "2) Localisation du mot-clé \"Yours sincerely\" : Ensuite, le mot-clé \"Yours sincerely\" est localisé dans l'image, car les signatures se trouvent systématiquement sous ce mot.\n",
        "\n",
        "3) Extraction des signatures : Une fois le mot-clé localisé, une extraction des signatures peut être réalisée en identifiant et capturant la zone sous ce mot dans l'image. Ce processus permet de détecter les régions où les signatures sont présentes.\n",
        "\n",
        "4) Extraction des noms après \"Yours sincerely\" : Après avoir localisé et extrait les signatures, le texte du PDF est analysé pour en extraire les noms présents après le mot-clé \"Yours sincerely\". Cela permet de récupérer les noms de toutes les personnes signant le document, y compris les noms des signataires et de l'assuré.\n",
        "\n",
        "5) Comparaison des noms extraits avec le nom de l'assuré : Si le nom de l'assuré est trouvé parmi les signataires, cela confirme que l'assuré a bien signé le document.\n",
        "\n",
        "6) Vérification de la présence de deux signatures : Enfin, la fonction vérifie que le document contient au moins deux signatures détectées sous le mot-clé \"Yours sincerely\". Si le nom de l'assuré est trouvé et que deux signatures sont présentes, cela confirme que le document est signé par les deux parties (y compris l'assuré)."
      ],
      "metadata": {
        "id": "sYoRAlCvDxuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation :"
      ],
      "metadata": {
        "id": "mnZCWclPBBVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!apt-get install -y libtesseract-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EeLmHJD63n-k",
        "outputId": "99c8109f-ecb2-4ceb-8635-68cd98b54c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Fetched 19.5 MB in 3s (6,258 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (409 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (5,410 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123660 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.3 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 1s (4,326 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123707 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oguJX-nI4RO",
        "outputId": "228225ed-74be-4ef8-b438-477b3da270b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9By92KJBb7",
        "outputId": "b8c4c91b-31eb-48cf-f53c-dfc97e0d1fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import re"
      ],
      "metadata": {
        "id": "PrhGTireBMMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Je vais utiliser pytesseract pour extraire du texte à partir d'images.\n",
        "# Tesseract est un moteur de reconnaissance optique de caractères (OCR) qui est utilisé pour extraire\n",
        "# du texte à partir d'images. La bibliothèque pytesseract permet d'interagir avec Tesseract depuis Python,\n",
        "# mais elle a besoin de connaître l'emplacement de l'exécutable de Tesseract pour fonctionner correctement.\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n"
      ],
      "metadata": {
        "id": "QdbG_S55BHkn"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction de conversion de la dernière page du PDF en image\n",
        "\n",
        "Cette fonction convertit la dernière page d'un fichier PDF en une image PNG. Elle utilise la bibliothèque pdf2image pour convertir le PDF en images et enregistre l'image de la dernière page dans un dossier de sortie. Le chemin de l'image enregistrée est ensuite retourné."
      ],
      "metadata": {
        "id": "Lgdi6BoWUcgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_last_page_to_image(pdf_path, output_folder=\"output_image\"):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    last_image = images[-1]\n",
        "    image_path = os.path.join(output_folder, \"last_page.png\")\n",
        "    last_image.save(image_path, \"PNG\")\n",
        "    return image_path"
      ],
      "metadata": {
        "id": "6Ok0iFWGCBDT"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction de recherche du mot-clé dans l'image\n",
        "\n",
        "Cette fonction permet de trouver la position de mot-clé: \"Yours sincerely\" dans l'image en utilisant l'OCR avec Tesseract.\n",
        "\n",
        "La fonction traite l'image, effectue l'OCR, et identifie la position du mot-clé dans l'image, en tenant compte du fait que le mot-clé pourrait être séparé en deux parties (\"Yours\" et \"sincerely\").\n",
        "\n"
      ],
      "metadata": {
        "id": "0nLWK0vYUo58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_keyword_position(image_path, keyword=\"Yours sincerely\"):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    data = pytesseract.image_to_data(gray, lang=\"eng\", output_type=pytesseract.Output.DICT)\n",
        "    keyword_parts = keyword.lower().split()\n",
        "    keyword_positions = []\n",
        "    current_position = None\n",
        "\n",
        "    for i, word in enumerate(data[\"text\"]):\n",
        "        if word.lower() == keyword_parts[0] and current_position is None:  # Première partie \"Yours\"\n",
        "            current_position = (data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i])\n",
        "        if word.lower() == keyword_parts[1] and current_position:  # Deuxième partie \"sincerely\"\n",
        "            x, y, w, h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n",
        "            keyword_positions.append((current_position[0], current_position[1], w, h))\n",
        "            break\n",
        "\n",
        "    return keyword_positions[0] if keyword_positions else None\n"
      ],
      "metadata": {
        "id": "4e_qEUgTEch_"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Détection des signatures après le mot-clé\n",
        "\n",
        "Cette fonction détecte les régions de signature dans une image, mais uniquement sous le mot-clé spécifié (par défaut \"Yours sincerely\").\n",
        "\n",
        "L'image est d'abord convertie en niveaux de gris et traitée pour détecter les contours. Ensuite, les régions en dessous du mot-clé sont extraites et enregistrées sous forme d'images.\n",
        "\n",
        "Les contours sont filtrés en fonction de leur taille pour ne conserver que ceux qui correspondent à des signatures.\n",
        "\n"
      ],
      "metadata": {
        "id": "iKcxOLr7U1Jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_signatures_after_keyword(image_path, keyword_position, output_folder=\"signatures\"):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    signature_regions = []\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    keyword_y = keyword_position[1] if keyword_position else 0\n",
        "\n",
        "    for i, contour in enumerate(contours):\n",
        "        area = cv2.contourArea(contour)\n",
        "        if 500 < area < 10000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            if y > keyword_y:\n",
        "                signature_regions.append((x, y, w, h))\n",
        "                roi = image[y:y+h, x:x+w]\n",
        "                region_path = os.path.join(output_folder, f\"signature_{i + 1}.png\")\n",
        "                cv2.imwrite(region_path, roi)\n",
        "\n",
        "    return signature_regions\n"
      ],
      "metadata": {
        "id": "dEx7uG_tF4_k"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction des Noms des Signataires\n",
        "\n",
        "Cette fonction extrait les noms situés après l'expression \"Yours sincerely\" dans un texte donné. Elle recherche les lignes contenant les noms et les nettoie des mots-clés tels que \"CEO\" ou \"Head\".\n",
        "\n",
        " Ensuite, la fonction normalize_name est utilisée pour normaliser les noms extraits en les convertissant en minuscules et en supprimant les espaces inutiles.\n",
        "\n",
        " La fonction check_name_in_extracted_list compare le nom de l'assuré, après l'avoir normalisé, avec les noms extraits pour vérifier si tous les mots du nom de l'assuré apparaissent dans les noms extraits."
      ],
      "metadata": {
        "id": "noK2pSe8Vm8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des noms après \"Yours sincerely\"\n",
        "def extract_names_after_sincerely(text):\n",
        "    pattern = r\"Yours sincerely\\s*(.*?)(?:\\n|\\r)(.*?)(?:\\n|\\r)\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        name_line_1 = match.group(1).strip()\n",
        "        name_line_2 = match.group(2).strip()\n",
        "\n",
        "        names = []\n",
        "        for line in [name_line_1, name_line_2]:\n",
        "            if not any(word in line for word in [\"CEO\", \"Head\"]):\n",
        "                names.append(line)\n",
        "\n",
        "        return names\n",
        "    return []\n",
        "\n",
        "# Fonction pour normaliser les noms\n",
        "def normalize_name(name):\n",
        "    return name.strip().lower()\n",
        "\n",
        "# Fonction pour vérifier si tous les mots du nom de l'assuré sont dans les noms extraits\n",
        "def check_name_in_extracted_list(insured_name, extracted_names):\n",
        "    # Normaliser le nom de l'assuré\n",
        "    normalized_insured_name = normalize_name(insured_name)\n",
        "    insured_name_parts = normalized_insured_name.split()\n",
        "\n",
        "    # Vérifier si tous les mots de l'assuré sont présents dans les noms extraits\n",
        "    for name in extracted_names:\n",
        "        normalized_extracted_name = normalize_name(name)\n",
        "        if all(part in normalized_extracted_name for part in insured_name_parts):\n",
        "            return True  # Si tous les mots sont trouvés dans ce nom\n",
        "    return False  # Si aucun nom n'est trouvé avec tous les mots"
      ],
      "metadata": {
        "id": "QFoQn5aAT1es"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "d6vGvZpUIPCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction principale pour traiter la dernière page et extraire les signatures et noms\n",
        "def process_last_page_for_signatures_after_keyword(pdf_path, insured_name, keyword=\"Yours sincerely\"):\n",
        "    last_page_image = convert_last_page_to_image(pdf_path)\n",
        "    keyword_position = find_keyword_position(last_page_image, keyword)\n",
        "\n",
        "    if keyword_position:\n",
        "        # Extraire les régions de signature\n",
        "        signature_regions = detect_signatures_after_keyword(last_page_image, keyword_position)\n",
        "\n",
        "        # Extraire le texte du PDF pour les noms\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            text = \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
        "\n",
        "        # Extraire les noms après \"Yours sincerely\"\n",
        "        extracted_names = extract_names_after_sincerely(text)\n",
        "\n",
        "        # print(f\"Extracted names from the document: {extracted_names}\")\n",
        "\n",
        "        # Vérifier si le nom de l'assuré est dans la liste des noms extraits\n",
        "        is_name_found = check_name_in_extracted_list(insured_name, extracted_names)\n",
        "\n",
        "        # Si le nom de l'assuré est trouvé dans la liste et qu'il y a plus de 2 signatures\n",
        "        if is_name_found and len(signature_regions) >= 2:\n",
        "            print(\"The document is signed by both parties.\")\n",
        "        else:\n",
        "            print(\"The document is not signed by both parties.\")\n",
        "    else:\n",
        "        print(f\"Keyword '{keyword}' not found in the last page.\")"
      ],
      "metadata": {
        "id": "hMVDnWjZT6rO"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/insurance-policy-example.pdf\"\n",
        "\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    text_first_page = pdf.pages[0].extract_text()\n",
        "\n",
        "    # Extraction du nom de l'assuré\n",
        "    insured_name = extract_name_and_address(text_first_page)[\"Nom de l'assuré\"]\n",
        "    print(f\"Insured's name extracted: {insured_name}\")\n",
        "\n",
        "\n",
        "process_last_page_for_signatures_after_keyword(pdf_path, insured_name, keyword=\"Yours sincerely\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFU4k7ua0uLP",
        "outputId": "09fc08dd-1a3e-42c2-aee8-a9c38fafc8bb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insured's name extracted: Charles Muster\n",
            "The document is not signed by both parties.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "Dans ce projet, j'ai utilisé des fonctions et des techniques spécifiques basées sur le modèle de contrat fourni pour extraire les entités et détecter les signatures. Cependant, si plusieurs modèles de contrats existent, il serait possible d'utiliser des systèmes LLMs (Large Language Models) associés à des mécanismes RAG (Retrieval-Augmented Generation). Ces systèmes peuvent analyser l'intégralité du texte, comprendre les informations présentes et, à la fin, générer automatiquement les entités souhaitées, indépendamment des variations de format ou de structure des documents."
      ],
      "metadata": {
        "id": "gZyok_s_ekGF"
      }
    }
  ]
}